            Sustainable Smart City Assistant â€“ A Text-to-Image Generator using Hugging Face APIs
Objective:
        The aim of this project is to design an AI-powered assistant that converts natural language 
descriptions into realistic images representing sustainable smart city concepts. 
The assistant aids urban planners, researchers, students, and educators to visualize futuristic 
eco-friendly infrastructure ideas.

Component	         Description
Streamlit:           Python framework for building and deploying web apps
Hugging Face API:	 Used to access hosted image generation models without local setup
Model Used:	         black-forest-labs/FLUX.1-dev â€“ High-performance SDXL-based diffusion model
Python Libraries:	 requests, PIL, io, base64, json, datetime

Key Functionalities:
1. ğŸ§¾ Prompt-Based Image Generation
Accepts user input as text (e.g., â€œSolar-powered smart homes with green rooftopsâ€).

Sends the input to the Hugging Face model API.

Displays the generated image in the web interface.

2. ğŸ–¼ï¸ Display & Download Image
Shows the generated image in the main interface.

Includes a Download button to save the image locally as PNG.

3. ğŸ’¬ Chat History Logging
Maintains a log of prompts and corresponding images.

Saves images as base64 in session for re-display and exporting.

4. ğŸ“œ History Export as JSON
Option to export the entire prompt-image chat history in .json format for record keeping.

5. ğŸ”‘ API Token Configuration
Secure field for entering Hugging Face API key.
Session state stores the token for reuse across app sessions.